{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from indicnlp.tokenize import indic_tokenize  \n",
    "from googletrans import Translator\n",
    "import spacy\n",
    "import re\n",
    "import html\n",
    "from spacy.lang.hi import STOP_WORDS as STOP_WORDS_HI\n",
    "from indicnlp.tokenize import indic_tokenize\n",
    "# import hindi_stemmer ##https://research.variancia.com/hindi_stemmer\n",
    "\n",
    "re1 = re.compile(r' +')\n",
    "data_path = \"hindi_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (4665, 5)\n"
     ]
    }
   ],
   "source": [
    "def get_train_test_from_tsv(tsv_name):\n",
    "    df = pd.read_csv(tsv_name, delimiter='\\t')\n",
    "    print(\"Dataset Shape: {}\".format(df.shape))\n",
    "    X_raw = df['text']\n",
    "    Y_raw = df['task_1']\n",
    "    return X_raw, Y_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_trans_hindi(X):\n",
    "    translator = Translator()\n",
    "    X_only_hindi = []\n",
    "    for i in range(len(X)):\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "        all_hindi_text = translator.translate(X[i], scr='hi', dest='hi').text\n",
    "        X_only_hindi.append(all_hindi_text)\n",
    "    return X_only_hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_preprocess(X):\n",
    "    X_stem = []\n",
    "    for i in range(len(X)):\n",
    "        if i%100==0:\n",
    "            print(i)\n",
    "        line = X[i]\n",
    "        tokens = indic_tokenize.trivial_tokenize(line)\n",
    "        tokens = [t for t in tokens if t not in STOP_WORDS_HI and not t.isnumeric() and not t.isalpha() and not t.isalnum()]\n",
    "        tokens = [t for t in tokens if t.isidentifier()]\n",
    "        tokens = [hi_stem(t) for t in tokens]\n",
    "        st = ' '.join(tokens)\n",
    "        X_stem.append(st)\n",
    "    return X_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (4665, 5)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n"
     ]
    }
   ],
   "source": [
    "X_, Y_ = get_train_test_from_tsv(\n",
    "    os.path.join(data_path, 'hasoc_19_train.tsv'))\n",
    "X_train_hindi = all_trans_hindi(X_)\n",
    "X_hindi_final = all_preprocess(X_train_hindi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_hindi = pd.DataFrame(\n",
    "    {'clean_text': X_hindi_final,\n",
    "     'label': Y_    })\n",
    "clean_hindi.to_csv(os.path.join(data_path,\"clean_hindi_train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (1318, 5)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n"
     ]
    }
   ],
   "source": [
    "X_, Y_ = get_train_test_from_tsv(\n",
    "    os.path.join(data_path, 'hasoc_19_gold.tsv'))\n",
    "X_hindi = all_trans_hindi(X_)\n",
    "X_hindi_final = all_preprocess(X_hindi)\n",
    "clean_hindi = pd.DataFrame(\n",
    "    {'clean_text': X_hindi_final,\n",
    "     'label': Y_    })\n",
    "clean_hindi.to_csv(os.path.join(data_path,\"clean_hindi_test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['कश्मीर',\n",
       " 'से',\n",
       " 'पत्थर',\n",
       " 'मार',\n",
       " 'पत्थरबाज',\n",
       " 'हमदर्द',\n",
       " 'लस्स',\n",
       " 'दे',\n",
       " 'मर्डर',\n",
       " 'लोग',\n",
       " 'पूछ',\n",
       " 'बाइक',\n",
       " 'चोर',\n",
       " 'क्य',\n",
       " 'पीट',\n",
       " 'तबरेज',\n",
       " 'पत्',\n",
       " 'मुआवज',\n",
       " 'नौकर',\n",
       " 'देग',\n",
       " 'दिल्ल',\n",
       " 'वक्फ',\n",
       " 'बोर्ड',\n",
       " 'तबरेज',\n",
       " 'मौत',\n",
       " 'मोद',\n",
       " 'जी',\n",
       " 'दुख',\n",
       " 'जत',\n",
       " 'ट्विंकल',\n",
       " '_',\n",
       " 'यादव']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_hindi_final[9].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
