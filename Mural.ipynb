{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xSVuKe-wBeLP",
    "outputId": "10a739d1-e41b-40c4-a009-2208dc155543"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
      "Requirement already satisfied: tensorflow<2.5,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-text) (2.4.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-text) (0.10.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (1.15.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (0.3.3)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (0.36.2)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (1.12)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (2.4.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (1.32.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (1.1.2)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (2.4.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (3.7.4.3)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (2.10.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (1.6.3)\n",
      "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (0.10.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (3.3.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (0.2.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (1.19.4)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (1.12.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (0.4.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (50.3.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (3.3.3)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (1.17.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (2.23.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (1.7.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (3.3.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (4.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (0.2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (3.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (3.4.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8pVpqFa3Fkfd",
    "outputId": "c3a0712e-ea57-4839-a769-50b5d91b4346"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-for-tf2 in /usr/local/lib/python3.6/dist-packages (0.14.7)\n",
      "Requirement already satisfied: py-params>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from bert-for-tf2) (0.9.7)\n",
      "Requirement already satisfied: params-flow>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from bert-for-tf2) (0.8.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-for-tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z3EqeEp6ts_Q",
    "outputId": "c493450a-6cea-46fb-970c-1e51d506ea3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Dataset Shape: (4665, 5)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.utils import all_estimators\n",
    "\n",
    "from google.colab import files\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def transform_label(raw_label):\n",
    "    return raw_label == 'HOF'\n",
    "\n",
    "\n",
    "def transform_Yset(Y_raw):\n",
    "    Y = []\n",
    "    for label in Y_raw:\n",
    "        Y.append(transform_label(label))\n",
    "    Y = np.asarray(Y)\n",
    "    return Y\n",
    "\n",
    "\n",
    "def get_train_test_from_tsv(tsv_name, train_data=True):\n",
    "    tsv_name = \"/content/drive/My Drive/mural_model/hindi_datasets/\"+tsv_name \n",
    "    df = pd.read_csv(tsv_name,delimiter=\"\\t\")\n",
    "    print(\"Dataset Shape: {}\".format(df.shape))\n",
    "    X_raw = df['text']\n",
    "    Y_raw = df['task_1']\n",
    "    # X_ = transform_Xset(X_raw)\n",
    "    # del (X_raw)\n",
    "    if train_data:\n",
    "      Y_ = transform_Yset(Y_raw)\n",
    "      del (df)\n",
    "      del (Y_raw)\n",
    "      return X_raw, Y_\n",
    "    else:\n",
    "      del (df)\n",
    "      return X_raw\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "BPSCsQIYgh9l"
   },
   "outputs": [],
   "source": [
    "#Reference # https://tfhub.dev/google/MuRIL/1 \n",
    "class OffenseMural():\n",
    "  def __init__(self):\n",
    "    self.max_seq_length = 128\n",
    "    self.model_url = \"https://tfhub.dev/google/MuRIL/1\"\n",
    "    self.bert_dim = 768\n",
    "    self.mlp_dim = 200\n",
    "    self.muril_model, self.muril_layer = self.get_model()\n",
    "    self.vocab_file = self.muril_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "    self.do_lower_case = self.muril_layer.resolved_object.do_lower_case.numpy()\n",
    "    self.tokenizer = bert_tokenization.FullTokenizer(self.vocab_file, self.do_lower_case)\n",
    "    # self.early_stopping_monitor = EarlyStopping(patience=3)\n",
    "    self.mlp = Sequential([Dense(units=self.mlp_dim,activation='relu',input_shape=(self.bert_dim,)),\n",
    "                           Dense(units=self.mlp_dim/2,activation='relu'),\n",
    "                           Dense(units=self.mlp_dim/4,activation='relu'),\n",
    "                           Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    self.mlp.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'], run_eagerly=True)\n",
    "\n",
    "  def get_model(self):\n",
    "    # Define input.\n",
    "      inputs = dict(\n",
    "          input_word_ids=tf.keras.layers.Input(shape=(self.max_seq_length,), dtype=tf.int32),\n",
    "          input_mask=tf.keras.layers.Input(shape=(self.max_seq_length,), dtype=tf.int32),\n",
    "          input_type_ids=tf.keras.layers.Input(shape=(self.max_seq_length,), dtype=tf.int32),\n",
    "      )\n",
    "    # Define muril layer.\n",
    "      muril_layer = hub.KerasLayer(self.model_url, trainable=False)\n",
    "      outputs = muril_layer(inputs)\n",
    "      assert 'sequence_output' in outputs and 'pooled_output' in outputs and 'encoder_outputs' in outputs and 'default' in outputs\n",
    "      return tf.keras.Model(inputs=inputs,outputs=outputs[\"pooled_output\"]), muril_layer\n",
    "\n",
    "### ref : tensorflow hub\n",
    "  def create_input(self, input_strings):\n",
    "    input_ids_all, input_mask_all, input_type_ids_all = [], [], []\n",
    "    for input_string in input_strings:\n",
    "      # Tokenize input.\n",
    "      input_tokens = [\"[CLS]\"] + self.tokenizer.tokenize(input_string) + [\"[SEP]\"]\n",
    "      input_ids = self.tokenizer.convert_tokens_to_ids(input_tokens)\n",
    "      sequence_length = min(len(input_ids), self.max_seq_length)\n",
    "      # Padding or truncation.\n",
    "      if len(input_ids) >= self.max_seq_length:\n",
    "        input_ids = input_ids[:self.max_seq_length]\n",
    "      else:\n",
    "        input_ids = input_ids + [0] * (self.max_seq_length - len(input_ids))\n",
    "      input_mask = [1] * sequence_length + [0] * (self.max_seq_length - sequence_length)\n",
    "      input_ids_all.append(input_ids)\n",
    "      input_mask_all.append(input_mask)\n",
    "      input_type_ids_all.append([0] * self.max_seq_length)\n",
    "\n",
    "    return np.array(input_ids_all), np.array(input_mask_all), np.array(input_type_ids_all)\n",
    "\n",
    "  def encode(self, input_text):\n",
    "      input_ids, input_mask, input_type_ids = self.create_input(input_text)\n",
    "      inputs = dict(\n",
    "          input_word_ids=input_ids,\n",
    "          input_mask=input_mask,\n",
    "          input_type_ids=input_type_ids,\n",
    "      )\n",
    "      return self.muril_model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "KhbUSKoNfD1q"
   },
   "outputs": [],
   "source": [
    "off_mural = OffenseMural()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b9Ri1ihSS1Xh",
    "outputId": "36133cd1-0d6b-41e6-c6c4-d153e4028add"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 200)               153800    \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 179,001\n",
      "Trainable params: 179,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "off_mural.mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "arY1-Yy52Z1g"
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = get_train_test_from_tsv(\"hasoc_19_train.tsv\")\n",
    "batch_size = 100\n",
    "num_batches_train = int(len(X_train)/batch_size)+1\n",
    "print(num_batches_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sfu3eAfo4taA",
    "outputId": "969f9797-8b7b-4249-82fd-609d916a87d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6725 - accuracy: 0.7800\n",
      "0 1 100 200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6702 - accuracy: 0.6600\n",
      "0 2 200 300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.6326 - accuracy: 0.8000\n",
      "0 3 300 400\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.5946 - accuracy: 0.8600\n",
      "0 4 400 500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6613 - accuracy: 0.6300\n",
      "0 5 500 600\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5801 - accuracy: 0.7900\n",
      "0 6 600 700\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6132 - accuracy: 0.7100\n",
      "0 7 700 800\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5736 - accuracy: 0.7600\n",
      "0 8 800 900\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7096 - accuracy: 0.5700\n",
      "0 9 900 1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5640 - accuracy: 0.7600\n",
      "0 10 1000 1100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6619 - accuracy: 0.6400\n",
      "0 11 1100 1200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7681 - accuracy: 0.5200\n",
      "0 12 1200 1300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.6858 - accuracy: 0.6100\n",
      "0 13 1300 1400\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5969 - accuracy: 0.7200\n",
      "0 14 1400 1500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.7310 - accuracy: 0.5300\n",
      "0 15 1500 1600\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6295 - accuracy: 0.6800\n",
      "0 16 1600 1700\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5773 - accuracy: 0.7700\n",
      "0 17 1700 1800\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5415 - accuracy: 0.8300\n",
      "0 18 1800 1900\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5711 - accuracy: 0.7700\n",
      "0 19 1900 2000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8494 - accuracy: 0.3600\n",
      "0 20 2000 2100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9185 - accuracy: 0.2500\n",
      "0 21 2100 2200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9718 - accuracy: 0.0900\n",
      "0 22 2200 2300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8776 - accuracy: 0.1500\n",
      "0 23 2300 2400\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7391 - accuracy: 0.4100\n",
      "0 24 2400 2500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6833 - accuracy: 0.5700\n",
      "0 25 2500 2600\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.6744 - accuracy: 0.6100\n",
      "0 26 2600 2700\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6714 - accuracy: 0.6300\n",
      "0 27 2700 2800\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7567 - accuracy: 0.2100\n",
      "0 28 2800 2900\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7611 - accuracy: 0.1600\n",
      "0 29 2900 3000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7230 - accuracy: 0.3400\n",
      "0 30 3000 3100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7334 - accuracy: 0.2400\n",
      "0 31 3100 3200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7384 - accuracy: 0.1600\n",
      "0 32 3200 3300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6925 - accuracy: 0.5200\n",
      "0 33 3300 3400\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7147 - accuracy: 0.2700\n",
      "0 34 3400 3500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.6909 - accuracy: 0.5400\n",
      "0 35 3500 3600\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.6966 - accuracy: 0.4500\n",
      "0 36 3600 3700\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6956 - accuracy: 0.4600\n",
      "0 37 3700 3800\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6938 - accuracy: 0.4900\n",
      "0 38 3800 3900\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7035 - accuracy: 0.2400\n",
      "0 39 3900 4000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.6999 - accuracy: 0.2800\n",
      "0 40 4000 4100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6986 - accuracy: 0.2200\n",
      "0 41 4100 4200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.6942 - accuracy: 0.4400\n",
      "0 42 4200 4300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6875 - accuracy: 0.8800\n",
      "0 43 4300 4400\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.6822 - accuracy: 0.8000\n",
      "0 44 4400 4500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6773 - accuracy: 0.7600\n",
      "0 45 4500 4600\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.6558 - accuracy: 0.9400\n",
      "0 46 4600 4700\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6566 - accuracy: 0.8462\n"
     ]
    }
   ],
   "source": [
    "epochs=1\n",
    "for epoch in range(epochs):\n",
    "  start = 0\n",
    "  end = 0\n",
    "  for batch in range(num_batches_train):\n",
    "    end = start + batch_size\n",
    "    print(epoch,batch, start, end)\n",
    "    X_batch_train = X_train[start:end]\n",
    "    Y_batch_train = Y_train[start:end]\n",
    "    embeddings_train = off_mural.encode(X_batch_train)\n",
    "    # print(embeddings_train.shape)\n",
    "    off_mural.mlp.fit(embeddings_train,Y_batch_train,shuffle=True)\n",
    "    start=end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JsS5L49uBK1C",
    "outputId": "6204d714-0a9c-428e-af19-0401ad1e941c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (1318, 5)\n",
      "3\n",
      "0 0 0 500\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6977 - accuracy: 0.4800\n",
      "0 1 500 1000\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.7002 - accuracy: 0.4600\n",
      "0 2 1000 1500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.7048 - accuracy: 0.4245\n"
     ]
    }
   ],
   "source": [
    "X_test, Y_test = get_train_test_from_tsv(\"hasoc_19_gold.tsv\")\n",
    "len(X_test)\n",
    "\n",
    "batch_size = 500\n",
    "num_batches_train = int(len(X_test)/batch_size)+1\n",
    "print(num_batches_train)\n",
    "\n",
    "epochs=1\n",
    "for epoch in range(epochs):\n",
    "  start = 0\n",
    "  end = 0\n",
    "  for batch in range(num_batches_train):\n",
    "    end = start + batch_size\n",
    "    print(epoch,batch, start, end)\n",
    "    X_batch_test = X_test[start:end]\n",
    "    Y_batch_test = Y_test[start:end]\n",
    "    embeddings_test = off_mural.encode(X_batch_test)\n",
    "    off_mural.mlp.evaluate(embeddings_test,Y_batch_test)\n",
    "    # print(embeddings_train.shape)\n",
    "    # off_mural.mlp.fit(embeddings_train,Y_batch_train,shuffle=True)\n",
    "    start=end"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Mural.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
